{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 - Exploring the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this chapter, you'll be introduced to the problem you'll be solving in this course. How do you accurately classify line-items in a school budget based on what that money is being used for? You will explore the raw text and numeric values in the dataset, both quantitatively and visually. And you'll learn how to measure success when trying to predict class labels for each row of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "Now it's time to check out the dataset! You'll use pandas to load your data into a DataFrame and then do some Exploratory Data Analysis (EDA) of it.\n",
    "\n",
    "The training data is available as TrainingData.csv. Your first task is to load it into a DataFrame in the IPython Shell using pd.read_csv() along with the keyword argument index_col=0.\n",
    "\n",
    "Use methods such as .info(), .head(), and .tail() to explore the budget data and the properties of the features and labels.\n",
    "\n",
    "Some of the column names correspond to features - descriptions of the budget items - such as the Job_Title_Description column. The values in this column tell us if a budget item is for a teacher, custodian, or other employee.\n",
    "\n",
    "Some columns correspond to the budget item labels you will be trying to predict with your model. For example, the Object_Type column describes whether the budget item is related classroom supplies, salary, travel expenses, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('TrainingData.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134338</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>50471.810</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206341</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>CONTRACTOR SERVICES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RGN  GOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDESIGNATED</td>\n",
       "      <td>3477.860</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326408</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>62237.130</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364634</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Benefits</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>EMPLOYEE BENEFITS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNALLOC BUDGETS/SCHOOLS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>22.300</td>\n",
       "      <td>GENERAL MIDDLE/JUNIOR HIGH SCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47683</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>TEACHER COVERAGE FOR TEACHER</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>54.166</td>\n",
       "      <td>GENERAL HIGH SCHOOL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Function          Use          Sharing Reporting  \\\n",
       "134338     Teacher Compensation  Instruction  School Reported    School   \n",
       "206341                 NO_LABEL     NO_LABEL         NO_LABEL  NO_LABEL   \n",
       "326408     Teacher Compensation  Instruction  School Reported    School   \n",
       "364634  Substitute Compensation  Instruction  School Reported    School   \n",
       "47683   Substitute Compensation  Instruction  School Reported    School   \n",
       "\n",
       "       Student_Type Position_Type               Object_Type     Pre_K  \\\n",
       "134338     NO_LABEL       Teacher                  NO_LABEL  NO_LABEL   \n",
       "206341     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "326408  Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
       "364634  Unspecified    Substitute                  Benefits  NO_LABEL   \n",
       "47683   Unspecified       Teacher   Substitute Compensation  NO_LABEL   \n",
       "\n",
       "         Operating_Status            Object_Description  \\\n",
       "134338  PreK-12 Operating                           NaN   \n",
       "206341      Non-Operating           CONTRACTOR SERVICES   \n",
       "326408  PreK-12 Operating  Personal Services - Teachers   \n",
       "364634  PreK-12 Operating             EMPLOYEE BENEFITS   \n",
       "47683   PreK-12 Operating  TEACHER COVERAGE FOR TEACHER   \n",
       "\n",
       "                    ...               Sub_Object_Description  \\\n",
       "134338              ...                                  NaN   \n",
       "206341              ...                                  NaN   \n",
       "326408              ...                                  NaN   \n",
       "364634              ...                                  NaN   \n",
       "47683               ...                                  NaN   \n",
       "\n",
       "       Location_Description  FTE     Function_Description  \\\n",
       "134338                  NaN  1.0                      NaN   \n",
       "206341                  NaN  NaN                 RGN  GOB   \n",
       "326408                  NaN  1.0                      NaN   \n",
       "364634                  NaN  NaN  UNALLOC BUDGETS/SCHOOLS   \n",
       "47683                   NaN  NaN              NON-PROJECT   \n",
       "\n",
       "       Facility_or_Department              Position_Extra      Total  \\\n",
       "134338                    NaN               KINDERGARTEN   50471.810   \n",
       "206341                    NaN                UNDESIGNATED   3477.860   \n",
       "326408                    NaN                     TEACHER  62237.130   \n",
       "364634                    NaN  PROFESSIONAL-INSTRUCTIONAL     22.300   \n",
       "47683                     NaN  PROFESSIONAL-INSTRUCTIONAL     54.166   \n",
       "\n",
       "                   Program_Description        Fund_Description  \\\n",
       "134338                    KINDERGARTEN            General Fund   \n",
       "206341   BUILDING IMPROVEMENT SERVICES                     NaN   \n",
       "326408           Instruction - Regular  General Purpose School   \n",
       "364634  GENERAL MIDDLE/JUNIOR HIGH SCH                     NaN   \n",
       "47683    GENERAL HIGH SCHOOL EDUCATION                     NaN   \n",
       "\n",
       "                               Text_1  \n",
       "134338                            NaN  \n",
       "206341  BUILDING IMPROVEMENT SERVICES  \n",
       "326408                            NaN  \n",
       "364634            REGULAR INSTRUCTION  \n",
       "47683             REGULAR INSTRUCTION  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type',\n",
       "       'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status',\n",
       "       'Object_Description', 'Text_2', 'SubFund_Description',\n",
       "       'Job_Title_Description', 'Text_3', 'Text_4', 'Sub_Object_Description',\n",
       "       'Location_Description', 'FTE', 'Function_Description',\n",
       "       'Facility_or_Department', 'Position_Extra', 'Total',\n",
       "       'Program_Description', 'Fund_Description', 'Text_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400277"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400277 entries, 134338 to 415831\n",
      "Data columns (total 25 columns):\n",
      "Function                  400277 non-null object\n",
      "Use                       400277 non-null object\n",
      "Sharing                   400277 non-null object\n",
      "Reporting                 400277 non-null object\n",
      "Student_Type              400277 non-null object\n",
      "Position_Type             400277 non-null object\n",
      "Object_Type               400277 non-null object\n",
      "Pre_K                     400277 non-null object\n",
      "Operating_Status          400277 non-null object\n",
      "Object_Description        375493 non-null object\n",
      "Text_2                    88217 non-null object\n",
      "SubFund_Description       306855 non-null object\n",
      "Job_Title_Description     292743 non-null object\n",
      "Text_3                    109152 non-null object\n",
      "Text_4                    53746 non-null object\n",
      "Sub_Object_Description    91603 non-null object\n",
      "Location_Description      162054 non-null object\n",
      "FTE                       126071 non-null float64\n",
      "Function_Description      342195 non-null object\n",
      "Facility_or_Department    53886 non-null object\n",
      "Position_Extra            264764 non-null object\n",
      "Total                     395722 non-null float64\n",
      "Program_Description       304660 non-null object\n",
      "Fund_Description          202877 non-null object\n",
      "Text_1                    292285 non-null object\n",
      "dtypes: float64(2), object(23)\n",
      "memory usage: 44.3+ MB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the data\n",
    "You'll continue your EDA in this exercise by computing summary statistics for the numeric data in the dataset. The data has been pre-loaded into a DataFrame called df.\n",
    "\n",
    "You can use df.info() in the IPython Shell to determine which columns of the data are numeric, specifically type float64. You'll notice that there are two numeric columns, called FTE and Total.\n",
    "\n",
    "- FTE: Stands for \"full-time equivalent\". If the budget item is associated to an employee, this number tells us the percentage of full-time that the employee works. A value of 1 means the associated employee works for the school full-time. A value close to 0 means the item is associated to a part-time or contracted employee.\n",
    "- Total: Stands for the total cost of the expenditure. This number tells us how much the budget item cost.\n",
    "After printing summary statistics for the numeric data, your job is to plot a histogram of the non-null FTE column to see the distribution of part-time and full-time employees in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126071.000000</td>\n",
       "      <td>3.957220e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.426794</td>\n",
       "      <td>1.310586e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.573576</td>\n",
       "      <td>3.682254e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.087551</td>\n",
       "      <td>-8.746631e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000792</td>\n",
       "      <td>7.379770e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.130927</td>\n",
       "      <td>4.612300e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.652662e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.800000</td>\n",
       "      <td>1.297000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FTE         Total\n",
       "count  126071.000000  3.957220e+05\n",
       "mean        0.426794  1.310586e+04\n",
       "std         0.573576  3.682254e+05\n",
       "min        -0.087551 -8.746631e+07\n",
       "25%         0.000792  7.379770e+01\n",
       "50%         0.130927  4.612300e+02\n",
       "75%         1.000000  3.652662e+03\n",
       "max        46.800000  1.297000e+08"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'num employees')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAElCAYAAAAyWE/9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xu8VVW99/HPV/CaKV7Qg4CCSSWZWZHR7WRqipfCU17wMUWzQ3bobsewOmmmz7FTXvIp7VigaCqS1RFLM1Ipu6hAXtGMHZps8SiKIJqp6O/5Y4yVk8Xae899mXvh2t/367Vee84xxxxzrLlh/fYYc6wxFBGYmZlVaYNmV8DMzFqfg42ZmVXOwcbMzCrnYGNmZpVzsDEzs8o52JiZWeUcbGy9JOl7kv6jj8raUdLTkgbl/XmSPtYXZefyrpM0ua/K68Z1T5f0uKT/7YOyXifpdkmrJX26RP6QtEvevljS6d241lq/DxsYHGys30l6UNKz+YNtpaTfSzpB0j/+PUbECRHx9ZJl7dtZnoh4KCI2j4gX+6Dup0r6YV35B0TEzN6W3c16jAROBMZGxD81Oi7pFkkrJJ1Vd+wXksbVnXISMC8iXh0R5/VxXdf6HfXl78NeORxsrFk+EBGvBnYCzgS+CEzv64tIGtzXZa4ndgKeiIjHOjh+MjATGA0cUgsuko4AlkTEggblLaqqsmYONtZUEbEqIuYARwCTJe0Ga3fNSNpW0s9yK2iFpJslbSDpUmBH4JrcLXOSpFG5i+d4SQ8BNxbSioHnNZJuk7RK0tWSts7X2ktSe7GOtb/MJU0AvgQcka93Zz7+j265XK+vSPqrpMckXSJpy3ysVo/Jkh7KXWBf7ujeSNoyn788l/eVXP6+wFxgh1yPixucPhq4MSJWAfOBnSVtAUzL76F4nRuB9wHfyeW9tr6rUdKxkn7bya+yo/fQ2e9ocOH+nZ5buE9LukbSNpIuk/SUpPmSRhXKfL2kufnfwv2SDu9uvaz/OdjYeiEibgPagfc0OHxiPjYU2J70YRkRcTTwEKmVtHlE/FfhnPcCuwL7d3DJY4CPAjsAa4Auu44i4hfA/wWuzNd7U4Nsx+bX+4Cdgc2B79TleTfwOmAf4KuSdu3gkv8P2DKX895c5+Mi4lfAAcCyXI9jG5x7D/B+SUOAccC9wNeBcyNiZd372hu4GfhkLu/PHd6Eburid1Q0CTgaGA68BvgDcBGwNXAfcAqApFeRAu3lwHbAkcD5kt7QV3W2ajjY2PpkGenDpd4LwDBgp4h4ISJujq4n9Ts1Ip6JiGc7OH5pRNwTEc8A/wEc3kcPrI8Czo6IJRHxNKk7a1Jdq+prEfFsRNwJ3AmsE7RyXY4ATo6I1RHxIHAW6QO5jP8kBe5fA98FNgR2J7UwLpf0G0mf7NlbrMRFEfGX3BK7DvhLRPwqItYAPwLenPMdDDwYERdFxJqI+CPwY+DQ5lTbynKwsfXJcGBFg/RvAm3ALyUtkTStRFlLu3H8r6QP421L1bJzO+TyimUPJrXIaoqjx/5Gav3U2xbYqEFZw8tUIiJWRMQRufX1bVIr6VOkbrR7gH2BEySNLVNeWUoj857Or6O6ceqjhe1nG+zX7tFOwNtzl+pKSStJAX6dQRK2fmnVh6f2CiPpbaQP0nWeC0TEalJX2om5u+QmSfMj4gagoxZOVy2fkYXtHUmtp8eBZ4DNCvUaROq+K1vuMtIHYrHsNaQPzxFdnFv0eK7TTqQusFpZD3ejjJopwC0RcY+kNwLnRMTzku4GdiuUX7TWfaDkh3lEHNAoubsV7sRS4NcR8f4+LNP6gVs21lSStpB0MDAL+GFE3N0gz8GSdpEk4CngxfyC9CG+cw8u/RFJYyVtBpwGXJWH4v4Z2ETSQZI2BL4CbFw471FglArDtOtcAXxO0mhJm/PyM5413alcrsts4AxJr5a0E/B54Iedn7k2SdsBU4FTc9IDwPty3cYBSzo49Q7gQ5I2U/o+zfHduW6dnv6OGvkZ8FpJR0vaML/e1slzL1tPONhYs1wjaTXpL9UvA2cDx3WQdwzwK+Bp0oPj8yNiXj72n8BXcpfKF7px/UuBi0ldWpsAn4Y0Og74N+AHpFbEM6TBCTU/yj+fkPTHBuXOyGX/hvTB/ndS91VPfCpffwmpxXd5Lr87vgWclp8fQbpfe5Pu+5wGQ6BrzgGeJwWKmcBl3bxuUU9/R+vIrdz9SAMKlpF+f99g7T8IbD0kL55mZmZVc8vGzMwq52BjZmaVc7AxM7PKOdiYmVnlHGzM+lij+dVaVf0camYdcbAxM7PKeQYBM+u2/AVbNbse9srhlo0NGJ1NTa+0pMH5hbm9fifpnySdK+lJSX+S9OZC/gclnSzp3nz8IkmbdHDdXXN300pJiyR9MKe/TdKjxUk6JX1Y0h15ewNJ0yT9RdITkmYrL4WQj4/P0/KvlHSnpL06uP5xkq4p7LdJml3YXyppj7z9zjyl/6r8852FfPMknSHpd6Q53Xauu84wSXfVvriptCzBEqVF8h7o5lxp1moiwi+/Wv4FvIr0rfnjSC36t5DmH3tDPn5x3n8raUaBG0kzABwDDAJOB24qlPcgaULLkaSZqn8HnJ6P7QW05+0NSZOIfok0sebewGrgdfn4vcABhXJ/CpyYtz8L3EKaU21j4L+BK/Kx4cATwIGkPxrfn/eHNnjvOwMrc75hpAk9Hy4cezIf2zpvH53v0ZF5f5ucdx5puYA35OMb5rSPAaNIU/1MKdzvpwrvc1jtXvs1MF9u2dhAUWZq+p9GxMKI+DvpQ//vEXFJpHnKruTlae5rvhMRSyNiBXAG6cO53njSjMVnRsTzEXEjaX6vWt6ZwEcAcqtlf9K0NAAfB74cEe0R8RxpfrNDc0voI8C1EXFtRLwUEXOBBaTgs5aIWEIKcHuQ1sW5HnhY0uvz/s0R8RJwELA4Ii7N9+gK4E/ABwrFXRwRi/LxF3LaWFLQOSUiLizkfQnYTdKmEfFIRHgl0AHMz2xsoPjH1PSFtMGkecxqyk5zX1O/TMEODa67A7A0f5gX89aWCvghcF+eGPNw0gf/I4U6/1RS8dwXScsV7AQcJqkYCDYEbmpQB0jr2uwF7JK3V5ICzTvyfq2uf607r35Zg0ZLNxxFar1dVUuIiGeUlqD+AjA9d72dGBF/6qB+1uLcsrGBojY1/ZDCa/OI+EQvyqxfpmBZgzzLgJF1s0T/Y6mAiHiYNLnov5C6r4rBbympi61Y503yOUtJC8AVj70qIs7soK61YFNbUO3XpGDzXl4ONvXLI6xV16zRZIqnkrogL1dhAbqIuD7SUgDDSC2k73dQNxsAHGxsoKhiavqpkkbk7q8vkbra6t1Kmrn5pHzNvUjdUrMKeS4BTgLeSOq+q/keaYmBnQAkDZU0MR/7IfABSftLGiRpk/z9no7WzPk1aanqTSOinbQM9ARgG+D2nOda0j36P5IG55bJWNK968wLwGGk5zSX5oEN20v6oNIyzs+RZux+sbNCrLU52NiAENVMTX858EvSEgBLSIMI6q/7PPBB4ADSX//nA8fUdSf9lNxlFmmZ6ppvA3NIK5SuJg0WeHsudykwkRTklpNaOv9OB/+nI+LPpA/8m/P+U7nOv8vPpIiIJ0jPtk4kDTY4CTg4Ih7v6kbk9/khYDvSMgiDcznLSKuvvpe0dIMNUF5iwKwHJD0IfCwiftVH5f0F+HhflWe2vnHLxqzJJH2Y9CzkxmbXxawqHo1m1kSS5pGeixxdN2LNrKW4G83MzCrnbjQzM6ucu9GybbfdNkaNGtXsapiZvaIsXLjw8YgY2lU+B5ts1KhRLFiwoNnVMDN7RZFUP+tEQ+5GMzOzyjnYmJlZ5RxszMyscg42ZmZWOQcbMzOrnIONmZlVzsHGzMwq52BjZmaVc7AxM7PKeQaBPjBq2s+bdu0Hzzyoadc2MyvLLRszM6ucg42ZmVXOwcbMzCrnYGNmZpVzsDEzs8pVFmwkzZD0mKR7CmnflPQnSXdJ+qmkIYVjJ0tqk3S/pP0L6RNyWpukaYX00ZJulbRY0pWSNsrpG+f9tnx8VFXv0czMyqmyZXMxMKEubS6wW0TsDvwZOBlA0lhgEvCGfM75kgZJGgR8FzgAGAscmfMCfAM4JyLGAE8Cx+f044EnI2IX4Jycz8zMmqiyYBMRvwFW1KX9MiLW5N1bgBF5eyIwKyKei4gHgDZgz/xqi4glEfE8MAuYKEnA3sBV+fyZwCGFsmbm7auAfXJ+MzNrkmY+s/kocF3eHg4sLRxrz2kdpW8DrCwErlr6WmXl46tyfjMza5KmBBtJXwbWAJfVkhpkix6kd1ZWo3pMkbRA0oLly5d3XmkzM+uxfg82kiYDBwNHRUQtCLQDIwvZRgDLOkl/HBgiaXBd+lpl5eNbUtedVxMRF0bEuIgYN3To0N6+NTMz60C/BhtJE4AvAh+MiL8VDs0BJuWRZKOBMcBtwHxgTB55thFpEMGcHKRuAg7N508Gri6UNTlvHwrcWAhqZmbWBJVNxCnpCmAvYFtJ7cAppNFnGwNz8zP7WyLihIhYJGk2cC+pe21qRLyYy/kkcD0wCJgREYvyJb4IzJJ0OnA7MD2nTwculdRGatFMquo9mplZOZUFm4g4skHy9AZptfxnAGc0SL8WuLZB+hLSaLX69L8Dh3WrsmZmVinPIGBmZpVzsDEzs8o52JiZWeUcbMzMrHIONmZmVjkHGzMzq5yDjZmZVc7BxszMKudgY2ZmlXOwMTOzyjnYmJlZ5RxszMyscg42ZmZWOQcbMzOrnIONmZlVzsHGzMwq52BjZmaVc7AxM7PKOdiYmVnlHGzMzKxyDjZmZlY5BxszM6ucg42ZmVXOwcbMzCpXWbCRNEPSY5LuKaRtLWmupMX551Y5XZLOk9Qm6S5JbymcMznnXyxpciH9rZLuzuecJ0mdXcPMzJqnypbNxcCEurRpwA0RMQa4Ie8DHACMya8pwAWQAgdwCvB2YE/glELwuCDnrZ03oYtrmJlZk1QWbCLiN8CKuuSJwMy8PRM4pJB+SSS3AEMkDQP2B+ZGxIqIeBKYC0zIx7aIiD9ERACX1JXV6BpmZtYk/f3MZvuIeAQg/9wupw8Hlhbytee0ztLbG6R3do11SJoiaYGkBcuXL+/xmzIzs86tLwME1CAtepDeLRFxYUSMi4hxQ4cO7e7pZmZWUn8Hm0dzFxj552M5vR0YWcg3AljWRfqIBumdXcPMzJqkv4PNHKA2omwycHUh/Zg8Km08sCp3gV0P7CdpqzwwYD/g+nxstaTxeRTaMXVlNbqGmZk1yeCqCpZ0BbAXsK2kdtKosjOB2ZKOBx4CDsvZrwUOBNqAvwHHAUTECklfB+bnfKdFRG3QwSdII942Ba7LLzq5hpmZNUllwSYijuzg0D4N8gYwtYNyZgAzGqQvAHZrkP5Eo2uYmVnzrC8DBMzMrIU52JiZWeUcbMzMrHIONmZmVjkHGzMzq5yDjZmZVc7BxszMKudgY2ZmlXOwMTOzyjnYmJlZ5RxszMyscg42ZmZWuW4FmzzV/+5VVcbMzFpTl8FG0jxJW0jaGrgTuEjS2dVXzczMWkWZls2WEfEU8CHgooh4K7BvtdUyM7NWUibYDM7LKx8O/Kzi+piZWQsqE2xOIy3P/JeImC9pZ2BxtdUyM7NW0uVKnRHxI+BHhf0lwIerrJSZmbWWMgMEXivpBkn35P3dJX2l+qqZmVmrKNON9n3gZOAFgIi4C5hUZaXMzKy1lAk2m0XEbXVpa6qojJmZtaYyweZxSa8BAkDSocAjldbKzMxaSpcDBICpwIXA6yU9DDwAfKTSWpmZWUspMxptCbCvpFcBG0TE6uqrZWZmraTMaLTtJU0HroqI1ZLGSjq+NxeV9DlJiyTdI+kKSZtIGi3pVkmLJV0paaOcd+O835aPjyqUc3JOv1/S/oX0CTmtTdK03tTVzMx6r8wzm4tJX+rcIe//GfhsTy8oaTjwaWBcROwGDCKNbvsGcE5EjAGeBGoB7XjgyYjYBTgn50PS2HzeG4AJwPmSBkkaBHwXOAAYCxyZ85qZWZOUCTbbRsRs4CWAiFgDvNjL6w4GNpU0GNiMNOBgb+CqfHwmcEjenpj3ycf3kaScPisinouIB4A2YM/8aouIJRHxPDAr5zUzsyYpE2yekbQNL49GGw+s6ukFI+Jh4FvAQ6QgswpYCKzMgQygHRiet4cDS/O5a3L+bYrpded0lL4OSVMkLZC0YPny5T19S2Zm1oUyweZEYA7wGkm/Ay4BPtXTC0raitTSGE3qmnsVqcurXtRO6eBYd9PXTYy4MCLGRcS4oUOHdlV1MzProTKj0RZKei/wOtIH+f0R8UIvrrkv8EBELAeQ9BPgncAQSYNz62UEsCznbwdGAu25221LYEUhvaZ4TkfpZmbWBGVGoy0ApgDLIuKeXgYaSN1n4yVtlp+97APcC9wEHJrzTAauzttz8j75+I0RETl9Uh6tNhoYA9wGzAfG5NFtG5EGEczpZZ3NzKwXynSjTSI985gvaZak/XOQ6JGIuJX0oP+PwN25DhcCXwQ+L6mN9Exmej5lOrBNTv88MC2XswiYTQpUvwCmRsSLuWX0SdIIuvuA2TmvmZk1iVIjoURGaQPgYOAC0si0GcC3I2JFddXrP+PGjYsFCxb06NxR037ex7Up78EzD2ratc3MJC2MiHFd5SvTskHS7sBZwDeBH5O6s54CbuxNJc3MbGDocoCApIXASlJ31rSIeC4fulXSu6qsnJmZtYYyE3EeludHW0dEfKiP62NmZi2oTDfaE5LOrn35UdJZkrasvGZmZtYyygSbGcBq4PD8egq4qMpKmZlZaynTjfaaiPhwYf9rku6oqkJmZtZ6yrRsnpX07tpOHhTwbHVVMjOzVlOmZfMJYGZ+TiPSVDHHVlkpMzNrLWXmRrsDeJOkLfL+U5XXyszMWkqHwUbS5ztIByAizq6oTmZm1mI6a9m8ut9qYWZmLa3DYBMRX+vPipiZWesqs8TAzpKukbRc0mOSrpa0c39UzszMWkOZoc+Xk6byH0ZaWfNHwBVVVsrMzFpLmWCjiLg0Itbk1w/pYJllMzOzRsp8z+YmSdOAWaQgcwTwc0lbA7TKejZmZladMsHmiPzz43XpHyUFHz+/MTOzTpX5Uufo/qiImZm1rjKLpw0CDgJGFfP7S51mZlZWmW60a4C/A3cDL1VbHTMza0Vlgs2IiNi98pqYmVnLKjP0+TpJ+1VeEzMza1llWja3AD+VtAHwAmmZgYiILSqtmZmZtYwyweYs4B3A3RHhL3OamVm3lelGWwzc05eBRtIQSVdJ+pOk+yS9Q9LWkuZKWpx/bpXzStJ5ktok3SXpLYVyJuf8iyVNLqS/VdLd+ZzzVFsXwczMmqJMsHkEmCfpZEmfr716ed1vA7+IiNcDbwLuA6YBN0TEGOCGvA9wADAmv6YAFwDkGQxOAd4O7AmcUgtQOc+UwnkTellfMzPrhTLB5gHSh/9GpDVuaq8eySt+/jMwHSAino+IlcBEYGbONhM4JG9PBC6J5BZgiKRhwP7A3IhYERFPAnOBCfnYFhHxh9wau6RQlpmZNUGZGQS+BiDpVRHxTB9cc2dgOXCRpDcBC4HPANtHxCP5mo9I2i7nHw4sLZzfntM6S29vkL4OSVNILSB23HHH3r0rMzPrUJn1bN4h6V5SVxeS3iTp/F5cczDwFuCCiHgz8Awvd5k1rEKDtOhB+rqJERdGxLiIGDd06NDOa21mZj1WphvtXFKX1RMAEXEnqRusp9qB9oi4Ne9fRQo+j+YuMPLPxwr5RxbOHwEs6yJ9RIN0MzNrkjLBhohYWpf0Yk8vGBH/CyyV9LqctA9wLzAHqI0omwxcnbfnAMfkUWnjgVW5u+16YD9JW+WBAfsB1+djqyWNz6PQjimUZWZmTVDmezZLJb0TCEkbAZ8md6n1wqeAy3J5S4DjSIFvtqTjgYeAw3Lea4EDgTbgbzkvEbFC0teB+TnfaYW1dT4BXAxsClyXX2Zm1iRlgs0JpKHKtQfvvwSm9uaiEXEHMK7BoX0a5I2OrhcRM4AZDdIXALv1po5mZtZ3yoxGexw4qh/qYmZmLarUMxszM7PecLAxM7PKOdiYmVnlyiwLPYQ0fHgUay8L/enqqmVmZq2kzGi0a0lr2nhZaDMz65EywWaTiOjtLM9mZjaAlXlmc6mkf5U0LK85s3We3t/MzKyUMi2b54FvAl/m5QktgzR7s5mZWZfKBJvPA7vkL3eamZl1W5lutEWkOcnMzMx6pEzL5kXgDkk3Ac/VEj302czMyioTbP4nv8zMzHqkzEScM/ujImZm1rrKzCDwAA2WVY4Ij0YzM7NSynSjFded2YS0qJm/Z2NmZqV1ORotIp4ovB6OiHOBvfuhbmZm1iLKdKO9pbC7Aaml8+rKamRmZi2nTDfaWYXtNcCDwOGV1MbMzFpSmdFo7+uPipiZWesq0422MfBh1l3P5rTqqmVmZq2kTDfa1cAqYCGFGQTMzMzKKhNsRkTEhMprYmZmLavMRJy/l/TGymtiZmYtq0yweTewUNL9ku6SdLeku3p7YUmDJN0u6Wd5f7SkWyUtlnSlpI1y+sZ5vy0fH1Uo4+Scfr+k/QvpE3Jam6Rpva2rmZn1TplutAMquvZngPuALfL+N4BzImKWpO8BxwMX5J9PRsQukiblfEdIGgtMAt4A7AD8StJrc1nfBd4PtAPzJc2JiHsreh9mZtaFMjMI/LXRqzcXlTQCOAj4Qd4XaVaCq3KWmcAheXti3icf3yfnnwjMiojnIuIBoA3YM7/aImJJRDwPzMp5zcysScp0o1XhXOAk4KW8vw2wMiLW5P12YHjeHg4sBcjHV+X8/0ivO6ej9HVImiJpgaQFy5cv7+17MjOzDvR7sJF0MPBYRCwsJjfIGl0c6276uokRF0bEuIgYN3To0E5qbWZmvVHmmU1fexfwQUkHkmaR3oLU0hkiaXBuvYwAluX87cBIoF3SYGBLYEUhvaZ4TkfpZmbWBP3esomIkyNiRESMIj3gvzEijgJuAg7N2SaTvkwKMCfvk4/fGBGR0yfl0WqjgTHAbcB8YEwe3bZRvsacfnhrZmbWgWa0bDryRWCWpNOB24HpOX06cKmkNlKLZhJARCySNBu4lzRB6NSIeBFA0ieB64FBwIyIWNSv78TMzNbS1GATEfOAeXl7CWkkWX2ev5MWbGt0/hnAGQ3SrwWu7cOqmplZLzRrNJqZmQ0gDjZmZlY5BxszM6ucg42ZmVXOwcbMzCrnYGNmZpVzsDEzs8o52JiZWeUcbMzMrHIONmZmVjkHGzMzq5yDjZmZVc7BxszMKudgY2ZmlXOwMTOzyjnYmJlZ5RxszMyscg42ZmZWOQcbMzOrnIONmZlVzsHGzMwq52BjZmaVc7AxM7PKOdiYmVnl+j3YSBop6SZJ90laJOkzOX1rSXMlLc4/t8rpknSepDZJd0l6S6GsyTn/YkmTC+lvlXR3Puc8Serv92lmZi9rRstmDXBiROwKjAemShoLTANuiIgxwA15H+AAYEx+TQEugBScgFOAtwN7AqfUAlTOM6Vw3oR+eF9mZtaBfg82EfFIRPwxb68G7gOGAxOBmTnbTOCQvD0RuCSSW4AhkoYB+wNzI2JFRDwJzAUm5GNbRMQfIiKASwplmZlZEzT1mY2kUcCbgVuB7SPiEUgBCdguZxsOLC2c1p7TOktvb5De6PpTJC2QtGD58uW9fTtmZtaBpgUbSZsDPwY+GxFPdZa1QVr0IH3dxIgLI2JcRIwbOnRoV1U2M7MeakqwkbQhKdBcFhE/ycmP5i4w8s/Hcno7MLJw+ghgWRfpIxqkm5lZkzRjNJqA6cB9EXF24dAcoDaibDJwdSH9mDwqbTywKnezXQ/sJ2mrPDBgP+D6fGy1pPH5WscUyjIzsyYY3IRrvgs4Grhb0h057UvAmcBsSccDDwGH5WPXAgcCbcDfgOMAImKFpK8D83O+0yJiRd7+BHAxsClwXX6ZmVmT9HuwiYjf0vi5CsA+DfIHMLWDsmYAMxqkLwB260U1zcysD3kGATMzq5yDjZmZVc7BxszMKudgY2ZmlXOwMTOzyjnYmJlZ5RxszMyscg42ZmZWOQcbMzOrnIONmZlVzsHGzMwq52BjZmaVc7AxM7PKOdiYmVnlHGzMzKxyDjZmZlY5BxszM6ucg42ZmVXOwcbMzCrnYGNmZpVzsDEzs8o52JiZWeUcbMzMrHIONmZmVrmWDTaSJki6X1KbpGnNro+Z2UDWksFG0iDgu8ABwFjgSEljm1srM7OBqyWDDbAn0BYRSyLieWAWMLHJdTIzG7AGN7sCFRkOLC3stwNvr88kaQowJe8+Len+XlxzW+DxXpzfI/pGf1+xU025B+uZgX4PBvr7h4F3D3Yqk6lVg40apMU6CREXAhf2yQWlBRExri/KeqXyPfA9GOjvH3wPOtKq3WjtwMjC/ghgWZPqYmY24LVqsJkPjJE0WtJGwCRgTpPrZGY2YLVkN1pErJH0SeB6YBAwIyIWVXzZPumOe4XzPfA9GOjvH3wPGlLEOo8yzMzM+lSrdqOZmdl6xMHGzMwq52DTSwNxWhxJMyQ9JumeQtrWkuZKWpx/btXMOlZN0khJN0m6T9IiSZ/J6QPmPkjaRNJtku7M9+BrOX20pFvzPbgyD9JpaZIGSbpd0s/y/oC7B11xsOmFATwtzsXAhLq0acANETEGuCHvt7I1wIkRsSswHpiaf/cD6T48B+wdEW8C9gAmSBoPfAM4J9+DJ4Hjm1jH/vIZ4L7C/kC8B51ysOmdATktTkT8BlhRlzwRmJm3ZwKH9Gul+llEPBIRf8zbq0kfNMMZQPchkqfz7ob5FcDewFU5vaXvAYCkEcBBwA/yvhhg96AMB5veaTQtzvAm1aXZto+IRyB9EAPbNbk+/UbSKODNwK0MsPuQu4/uAB4D5gJ/AVZGxJqcZSD8nzgXOAl4Ke9vw8C7B11ysOmdUtPiWOuStDnwY+CzEfFUs+vT3yLixYjYgzRLx57Aro2y9W+t+o+kg4HHImJhMblB1pa9B2W15Jc6+5GnxXnZo5KGRcQjkoaR/tIrnyt/AAADpklEQVRtaZI2JAWayyLiJzl5wN0HgIhYKWke6fnVEEmD81/2rf5/4l3AByUdCGwCbEFq6Qyke1CKWza942lxXjYHmJy3JwNXN7Eulcv98tOB+yLi7MKhAXMfJA2VNCRvbwrsS3p2dRNwaM7W0vcgIk6OiBERMYr0///GiDiKAXQPyvIMAr2U/6I5l5enxTmjyVWqnKQrgL1IU6k/CpwC/A8wG9gReAg4LCLqBxG0DEnvBm4G7ublvvovkZ7bDIj7IGl30sPvQaQ/XGdHxGmSdiYNltkauB34SEQ817ya9g9JewFfiIiDB+o96IyDjZmZVc7daGZmVjkHGzMzq5yDjZmZVc7BxszMKudgY2ZmlXOwMetE/i7JbyXdI+mQQvrVknboQVm35tmB31N37D155uQ78ndWOipjnqRxeftBSds2yLOXpHcW9k+QdEx36mrW1xxszDp3JOm7JO8A/h1A0geAP0ZEd78Vvg/wp4h4c0TcXHfsKOBbEbFHRDzbyzrvBfwj2ETE9yLikl6WadYrDjZmnXsB2BTYGHhJ0mDgs8A3OzpB0k6SbpB0V/65o6Q9gP8CDqxvvUj6GHA48FVJl+WWyc8Kx78j6dgylc2Tgp4AfC5f5z2STpX0hXx8nqRzJP0mr8XzNkk/yeuunF4o5yN5rZo7JP13Xk7DrMccbMw6dzmwP/AL4FTg34BLIuJvnZzznZxnd+Ay4LyIuAP4KnBlfeslIn5Amubm3/NUJz0WEQ8C3yOtpbJHgxYUwPMR8c8539XAVGA34FhJ20jaFTgCeFeeZPNFUsvLrMc8EadZJyJiFWmtEvKqm18EPiTp+8BWwFkR8Ye6094BfChvX0pq0axPavP33Q0sqi2JIGkJaWLZdwNvBeanKeDYlAEyoahVx8HGrLyvAmeQnuMsJLV6rgbe18V53Z0Tag1r9zps0llmSVOBf827B5YovzZH10uF7dr+YNIU+TMj4uRStTUrwd1oZiVIGgPsEBG/BjYjfTAHjQPB70kzAEPqfvptNy/3V2CspI0lbUkaWNChiPhu7jLbIw9aWA28upvXLLoBOFTSdgCStpa0Uy/KM3OwMSvpDOArefsK4FjgFuBbDfJ+GjhO0l3A0aT16UuLiKWkmaPvIj3zub2bdb0G+JfaAIFunktE3Et6r7/M72EuMKy75ZgVedZnMzOrnFs2ZmZWOQcbMzOrnIONmZlVzsHGzMwq52BjZmaVc7AxM7PKOdiYmVnl/j9cg6EU8EU8KQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the histogram\n",
    "plt.hist(training_df['FTE'].dropna())\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring datatypes in pandas\n",
    "It's always good to know what datatypes you're working with, especially when the inefficient pandas type object may be involved. Towards that end, let's explore what we have.\n",
    "\n",
    "The data has been loaded into the workspace as df. Your job is to look at the DataFrame attribute .dtypes in the IPython Shell, and call its .value_counts() method in order to answer the question below.\n",
    "\n",
    "Make sure to call df.dtypes.value_counts(), and not df.value_counts()! Check out the difference in the Shell. df.value_counts() will return an error, because it is a Series method, not a DataFrame method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function                   object\n",
       "Use                        object\n",
       "Sharing                    object\n",
       "Reporting                  object\n",
       "Student_Type               object\n",
       "Position_Type              object\n",
       "Object_Type                object\n",
       "Pre_K                      object\n",
       "Operating_Status           object\n",
       "Object_Description         object\n",
       "Text_2                     object\n",
       "SubFund_Description        object\n",
       "Job_Title_Description      object\n",
       "Text_3                     object\n",
       "Text_4                     object\n",
       "Sub_Object_Description     object\n",
       "Location_Description       object\n",
       "FTE                       float64\n",
       "Function_Description       object\n",
       "Facility_or_Department     object\n",
       "Position_Extra             object\n",
       "Total                     float64\n",
       "Program_Description        object\n",
       "Fund_Description           object\n",
       "Text_1                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     23\n",
       "float64     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels as categorical variables\n",
    "Remember, your ultimate goal is to predict the probability that a certain label is attached to a budget line item. You just saw that many columns in your data are the inefficient object type. Does this include the labels you're trying to predict? Let's find out!\n",
    "\n",
    "There are 9 columns of labels in the dataset. Each of these columns is a category that has many possible values it can take. The 9 labels have been loaded into a list called LABELS. In the Shell, check out the type for these labels using df[LABELS].dtypes.  \n",
    "\n",
    "You will notice that every label is encoded as an object datatype. Because category datatypes are much more efficient your task is to convert the labels to category types using the .astype() method.\n",
    "\n",
    "Note: .astype() only works on a pandas Series. Since you are working with a pandas DataFrame, you'll need to use the .apply() method and provide a lambda function called categorize_label that applies .astype() to each column, x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Function','Use','Sharing','Reporting','Student_Type','Position_Type','Object_Type','Pre_K','Operating_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function            object\n",
       "Use                 object\n",
       "Sharing             object\n",
       "Reporting           object\n",
       "Student_Type        object\n",
       "Position_Type       object\n",
       "Object_Type         object\n",
       "Pre_K               object\n",
       "Operating_Status    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df[LABELS].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Use                 category\n",
      "Sharing             category\n",
      "Reporting           category\n",
      "Student_Type        category\n",
      "Position_Type       category\n",
      "Object_Type         category\n",
      "Pre_K               category\n",
      "Operating_Status    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the lambda function: categorizfe_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert training_df[LABELS] to a categorical type\n",
    "training_df[LABELS] = training_df[LABELS].apply(categorize_label, axis = 0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(training_df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting unique labels\n",
    "There are over 100 unique labels. In this exercise, you will explore this fact by counting and plotting the number of unique values for each category of label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of unique values')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_labels = training_df[LABELS].apply(pd.Series.nunique)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "num_unique_labels.plot(kind = 'bar')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Woah! That's a lot of labels to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing log loss with NumPy\n",
    "To see how the log loss metric handles the trade-off between accuracy and confidence, we will use some sample data generated with NumPy and compute the log loss using the provided function compute_log_loss(), which Peter showed you in the video.\n",
    "\n",
    "5 one-dimensional numeric arrays simulating different types of predictions have been pre-loaded: actual_labels, correct_confident, correct_not_confident, wrong_not_confident, and wrong_confident.\n",
    "\n",
    "Your job is to compute the log loss for each sample set provided using the compute_log_loss(predicted_values, actual_values). It takes the predicted values as the first argument and the actual values as the second argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_confident = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.05])\n",
    "correct_not_confident = np.array([0.65, 0.65, 0.65, 0.65, 0.65, 0.35, 0.35, 0.35, 0.35, 0.35])\n",
    "wrong_not_confident = np.array([0.35, 0.35, 0.35, 0.35, 0.35, 0.65, 0.65, 0.65, 0.65, 0.65])\n",
    "wrong_confident = np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.95, 0.95, 0.95, 0.95, 0.95])\n",
    "actual_labels = np.array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_loss(predicted, actual, eps = 1e-14):\n",
    "    \"\"\" Compute the logarithmic loss between predicted and \n",
    "        actual when they are 1D arrays.\n",
    "        \n",
    "        :param predicted: The predicted probabilities as floats between 0-1\n",
    "        :param actual: The actual binary labels. Either 1 or 0\n",
    "        :param eps (optional): log(0) in inf, so we need to offset our\n",
    "                               predicted values slightly by eps from 0 or 1.\n",
    "    \"\"\"\n",
    "    predicted = np.clip(predicted, eps, 1 - eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted)\n",
    "              + (1 - actual)\n",
    "              * np.log(1 - predicted))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss, correct and confident: 0.05129329438755058\n",
      "Log loss, correct and not confident: 0.4307829160924542\n",
      "Log loss, wrong and not confident: 1.049822124498678\n",
      "Log loss, wrong and confident: 2.9957322735539904\n",
      "Log loss, actual labels: 9.99200722162646e-15\n"
     ]
    }
   ],
   "source": [
    "# Compute and print log loss for 1st case\n",
    "correct_confident = compute_log_loss(correct_confident, actual_labels)\n",
    "print(\"Log loss, correct and confident: {}\".format(correct_confident)) \n",
    "\n",
    "# Compute log loss for 2nd case\n",
    "correct_not_confident = compute_log_loss(correct_not_confident, actual_labels)\n",
    "print(\"Log loss, correct and not confident: {}\".format(correct_not_confident)) \n",
    "\n",
    "# Compute and print log loss for 3rd case\n",
    "wrong_not_confident = compute_log_loss(wrong_not_confident, actual_labels)\n",
    "print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident)) \n",
    "\n",
    "# Compute and print log loss for 4th case\n",
    "wrong_confident = compute_log_loss(wrong_confident, actual_labels)\n",
    "print(\"Log loss, wrong and confident: {}\".format(wrong_confident)) \n",
    "\n",
    "# Compute and print log loss for actual labels\n",
    "actual_labels = compute_log_loss(actual_labels, actual_labels)\n",
    "print(\"Log loss, actual labels: {}\".format(actual_labels)) \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Wow! Log loss penalizes highly confident wrong answers much more than any other type. This will be a good metric to use on your models. You rock!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 - Creating a simple first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this chapter, you'll build a first-pass model. You'll use numeric data only to train the model. Spoiler alert - throwing out all of the text data is bad for performance! But you'll learn how to format your predictions. Then, you'll be introduced to natural language processing (NLP) in order to start working with the large amounts of text in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a train-test split in scikit-learn\n",
    "Alright, you've been patient and awesome. It's finally time to start training models!\n",
    "\n",
    "The first step is to split the data into a training set and a test set. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. We provide a function that will make sure at least min_count examples of each label appear in each split: multilabel_train_test_split.\n",
    "\n",
    "Feel free to check out the full code for multilabel_train_test_split here.\n",
    "\n",
    "\n",
    "\n",
    "You'll start with a simple model that uses just the numeric columns of your DataFrame when calling multilabel_train_test_split. The data has been read into a DataFrame df and a list consisting of just the numeric columns is available as NUMERIC_COLUMNS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.multilabel import multilabel_train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instructions__\n",
    "- Create a new DataFrame named numeric_data_only by applying the .fillna(-1000) method to the numeric columns (available in the list NUMERIC_COLUMNS) of df.\n",
    "- Convert the labels (available in the list LABELS) to dummy variables. Save the result as label_dummies.\n",
    "- In the call to multilabel_train_test_split(), set the size of your test set to be 0.2. Use a seed of 123.\n",
    "- Fill in the .info() method calls for X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Data columns (total 2 columns):\n",
      "FTE      320222 non-null float64\n",
      "Total    320222 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 72072\n",
      "Data columns (total 2 columns):\n",
      "FTE      80055 non-null float64\n",
      "Total    80055 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 34.2 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 72072\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the new DataFrame: numeric_data_only\n",
    "numeric_data_only = training_df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(training_df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,label_dummies,size=0.2,seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nice! With the data split, you can now train a model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "With split data in hand, you're only a few lines away from training a model.\n",
    "\n",
    "In this exercise, you will import the logistic regression and one versus rest classifiers in order to fit a multi-class logistic regression model to the NUMERIC_COLUMNS of your feature data.\n",
    "\n",
    "Then you'll test and print the accuracy with the .score() method to see the results of training.\n",
    "\n",
    "Before you train! Remember, we're ultimately going to be using logloss to score our model, so don't worry too much about the accuracy here. Keep in mind that you're throwing away all of the text data in the dataset - that's by far most of the data! So don't get your hopes up for a killer performance just yet. We're just interested in getting things up and running at the moment.\n",
    "\n",
    "All data necessary to call multilabel_train_test_split() has been loaded into the workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instructions__\n",
    "- Import LogisticRegression from sklearn.linear_model and OneVsRestClassifier from sklearn.multiclass.\n",
    "- Instantiate the classifier clf by placing LogisticRegression() inside OneVsRestClassifier().\n",
    "- Fit the classifier to the training data X_train and y_train.\n",
    "- Compute and print the accuracy of the classifier using its .score() method, which accepts two arguments: X_test and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ok! The good news is that your workflow didn't cause any errors. The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your model to predict values on holdout data\n",
    "You're ready to make some predictions! Remember, the train-test-split you've carried out so far is for model development. The original competition provides an additional test set, for which you'll never actually see the correct labels. This is called the \"holdout data.\"\n",
    "\n",
    "The point of the holdout data is to provide a fair test for machine learning competitions. If the labels aren't known by anyone but DataCamp, DrivenData, or whoever is hosting the competition, you can be sure that no one submits a mere copy of labels to artificially pump up the performance on their model.\n",
    "\n",
    "Remember that the original goal is to predict the probability of each label. In this exercise you'll do just that by using the .predict_proba() method on your trained model.\n",
    "\n",
    "First, however, you'll need to load the holdout data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('TestData.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions using .predict_proba() on the numeric columns (available in the NUMERIC_COLUMNS list) of test_df. Make sure to fill in missing values with -1000!\n",
    "predictions = clf.predict_proba(test_df[NUMERIC_COLUMNS].fillna(-1000))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Awesome! Now you can write the predictions to a .csv and submit for scoring!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out your results to a csv for submission\n",
    "At last, you're ready to submit some predictions for scoring. In this exercise, you'll write your predictions to a .csv using the .to_csv() method on a pandas DataFrame. Then you'll evaluate your performance according to the LogLoss metric discussed earlier!\n",
    "\n",
    "You'll need to make sure your submission obeys the correct format.\n",
    "\n",
    "To do this, you'll use your predictions values to create a new DataFrame, prediction_df.\n",
    "\n",
    "Interpreting LogLoss & Beating the Benchmark:\n",
    "\n",
    "When interpreting your log loss score, keep in mind that the score will change based on the number of samples tested. To get a sense of how this very basic model performs, compare your score to the DrivenData benchmark model performance: 2.0455, which merely submitted uniform probabilities for each class.\n",
    "\n",
    "Remember, the lower the log loss the better. Is your model's log loss lower than 2.0455?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instructions__\n",
    "- Create the prediction_df DataFrame by specifying the following arguments to the provided parameters pd.DataFrame():\n",
    "    - pd.get_dummies(df[LABELS]).columns.\n",
    "    - test_df.index.\n",
    "    - predictions.\n",
    "- Save prediction_df to a csv file called 'predictions.csv' using the .to_csv() method.\n",
    "- Submit the predictions for scoring by using the score_submission() function with pred_path set to 'predictions.csv'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(test_df[NUMERIC_COLUMNS].fillna(-1000))\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(training_df[LABELS]).columns,\n",
    "                             index=test_df.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('predictions.csv')\n",
    "\n",
    "# Submit the predictions for scoring: score\n",
    "#score = score_submission(pred_path='predictions.csv')\n",
    "\n",
    "# Print score\n",
    "#print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_submission(pred_path='predictions.csv', holdout_path='https://s3.amazonaws.com/assets.datacamp.com/production/course_2826/datasets/TestSetLabelsSample.csv')\n",
    "#Source:\n",
    "def score_submission(pred_path='predictions.csv', holdout_path='https://s3.amazonaws.com/assets.datacamp.com/production/course_2826/datasets/TestSetLabelsSample.csv'):\n",
    "    # this happens on the backend to get the score\n",
    "    holdout_labels = pd.get_dummies(\n",
    "                        pd.read_csv(holdout_path, index_col=0)\n",
    "                          .apply(lambda x: x.astype('category'), axis=0)\n",
    "                      )\n",
    "\n",
    "    preds = pd.read_csv(pred_path, index_col=0)\n",
    "    \n",
    "    # make sure that format is correct\n",
    "    assert (preds.columns == holdout_labels.columns).all()\n",
    "    assert (preds.index == holdout_labels.index).all()\n",
    "\n",
    "    return _multi_multi_log_loss(preds.values, holdout_labels.values)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Incredible! Even though your basic model scored 0.0 accuracy, it nevertheless performs better than the benchmark score of 2.0455. You've now got the basics down and have made a first pass at this complicated supervised learning problem. It's time to step up your game and incorporate the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a bag-of-words in scikit-learn\n",
    "In this exercise, you'll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns.\n",
    "\n",
    "You will focus on one feature only, the Position_Extra column, which describes any additional information not captured by the Position_Type label.\n",
    "\n",
    "For example, in the Shell you can check out the budget item in row 8960 of the data using df.loc[8960]. Looking at the output reveals that this Object_Description is overtime pay. For who? The Position Type is merely \"other\", but the Position Extra elaborates: \"BUS DRIVER\". Explore the column further to see more instances. It has a lot of NaN values.\n",
    "\n",
    "Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.\n",
    "\n",
    "For comparison purposes, the first 15 tokens of vec_basic, which splits df.Position_Extra into tokens when it encounters only whitespace characters, have been printed along with the length of the representation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Function_Aides Compensation</th>\n",
       "      <th>Function_Career &amp; Academic Counseling</th>\n",
       "      <th>Function_Communications</th>\n",
       "      <th>Function_Curriculum Development</th>\n",
       "      <th>Function_Data Processing &amp; Information Services</th>\n",
       "      <th>Function_Development &amp; Fundraising</th>\n",
       "      <th>Function_Enrichment</th>\n",
       "      <th>Function_Extended Time &amp; Tutoring</th>\n",
       "      <th>Function_Facilities &amp; Maintenance</th>\n",
       "      <th>...</th>\n",
       "      <th>Object_Type_Rent/Utilities</th>\n",
       "      <th>Object_Type_Substitute Compensation</th>\n",
       "      <th>Object_Type_Supplies/Materials</th>\n",
       "      <th>Object_Type_Travel &amp; Conferences</th>\n",
       "      <th>Pre_K_NO_LABEL</th>\n",
       "      <th>Pre_K_Non PreK</th>\n",
       "      <th>Pre_K_PreK</th>\n",
       "      <th>Operating_Status_Non-Operating</th>\n",
       "      <th>Operating_Status_Operating, Not PreK-12</th>\n",
       "      <th>Operating_Status_PreK-12 Operating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180042</td>\n",
       "      <td>0.035842</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.032077</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>0.052099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.036846</td>\n",
       "      <td>0.116126</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.831241</td>\n",
       "      <td>0.141031</td>\n",
       "      <td>0.027749</td>\n",
       "      <td>0.169612</td>\n",
       "      <td>0.019930</td>\n",
       "      <td>0.810543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28872</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.032078</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>0.052102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.036959</td>\n",
       "      <td>0.116164</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.831233</td>\n",
       "      <td>0.141041</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>0.169607</td>\n",
       "      <td>0.019930</td>\n",
       "      <td>0.810553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186915</td>\n",
       "      <td>0.120947</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.028599</td>\n",
       "      <td>0.016041</td>\n",
       "      <td>0.019549</td>\n",
       "      <td>0.043858</td>\n",
       "      <td>0.031715</td>\n",
       "      <td>0.113907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.136221</td>\n",
       "      <td>0.135391</td>\n",
       "      <td>0.016041</td>\n",
       "      <td>0.501655</td>\n",
       "      <td>0.472173</td>\n",
       "      <td>0.098601</td>\n",
       "      <td>0.095922</td>\n",
       "      <td>0.051039</td>\n",
       "      <td>0.928357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>412396</td>\n",
       "      <td>0.120381</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.019517</td>\n",
       "      <td>0.043808</td>\n",
       "      <td>0.031688</td>\n",
       "      <td>0.113723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.125189</td>\n",
       "      <td>0.134056</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>0.502143</td>\n",
       "      <td>0.471525</td>\n",
       "      <td>0.098399</td>\n",
       "      <td>0.096025</td>\n",
       "      <td>0.051012</td>\n",
       "      <td>0.928230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>427740</td>\n",
       "      <td>0.121725</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>0.019593</td>\n",
       "      <td>0.043926</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>0.114158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.152629</td>\n",
       "      <td>0.137236</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.500987</td>\n",
       "      <td>0.473061</td>\n",
       "      <td>0.098879</td>\n",
       "      <td>0.095781</td>\n",
       "      <td>0.051075</td>\n",
       "      <td>0.928531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Function_Aides Compensation  \\\n",
       "0      180042                     0.035842   \n",
       "1       28872                     0.035848   \n",
       "2      186915                     0.120947   \n",
       "3      412396                     0.120381   \n",
       "4      427740                     0.121725   \n",
       "\n",
       "   Function_Career & Academic Counseling  Function_Communications  \\\n",
       "0                               0.006466                 0.000830   \n",
       "1                               0.006466                 0.000830   \n",
       "2                               0.009065                 0.001542   \n",
       "3                               0.009071                 0.001541   \n",
       "4                               0.009057                 0.001543   \n",
       "\n",
       "   Function_Curriculum Development  \\\n",
       "0                         0.023918   \n",
       "1                         0.023918   \n",
       "2                         0.028599   \n",
       "3                         0.028573   \n",
       "4                         0.028634   \n",
       "\n",
       "   Function_Data Processing & Information Services  \\\n",
       "0                                         0.008916   \n",
       "1                                         0.008916   \n",
       "2                                         0.016041   \n",
       "3                                         0.016043   \n",
       "4                                         0.016038   \n",
       "\n",
       "   Function_Development & Fundraising  Function_Enrichment  \\\n",
       "0                            0.000181             0.032077   \n",
       "1                            0.000181             0.032078   \n",
       "2                            0.019549             0.043858   \n",
       "3                            0.019517             0.043808   \n",
       "4                            0.019593             0.043926   \n",
       "\n",
       "   Function_Extended Time & Tutoring  Function_Facilities & Maintenance  \\\n",
       "0                           0.024406                           0.052099   \n",
       "1                           0.024406                           0.052102   \n",
       "2                           0.031715                           0.113907   \n",
       "3                           0.031688                           0.113723   \n",
       "4                           0.031752                           0.114158   \n",
       "\n",
       "                  ...                  Object_Type_Rent/Utilities  \\\n",
       "0                 ...                                    0.010729   \n",
       "1                 ...                                    0.010728   \n",
       "2                 ...                                    0.005622   \n",
       "3                 ...                                    0.005630   \n",
       "4                 ...                                    0.005612   \n",
       "\n",
       "   Object_Type_Substitute Compensation  Object_Type_Supplies/Materials  \\\n",
       "0                             0.036846                        0.116126   \n",
       "1                             0.036959                        0.116164   \n",
       "2                             0.136221                        0.135391   \n",
       "3                             0.125189                        0.134056   \n",
       "4                             0.152629                        0.137236   \n",
       "\n",
       "   Object_Type_Travel & Conferences  Pre_K_NO_LABEL  Pre_K_Non PreK  \\\n",
       "0                          0.017360        0.831241        0.141031   \n",
       "1                          0.017361        0.831233        0.141041   \n",
       "2                          0.016041        0.501655        0.472173   \n",
       "3                          0.016029        0.502143        0.471525   \n",
       "4                          0.016059        0.500987        0.473061   \n",
       "\n",
       "   Pre_K_PreK  Operating_Status_Non-Operating  \\\n",
       "0    0.027749                        0.169612   \n",
       "1    0.027751                        0.169607   \n",
       "2    0.098601                        0.095922   \n",
       "3    0.098399                        0.096025   \n",
       "4    0.098879                        0.095781   \n",
       "\n",
       "   Operating_Status_Operating, Not PreK-12  Operating_Status_PreK-12 Operating  \n",
       "0                                 0.019930                            0.810543  \n",
       "1                                 0.019930                            0.810553  \n",
       "2                                 0.051039                            0.928357  \n",
       "3                                 0.051012                            0.928230  \n",
       "4                                 0.051075                            0.928531  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instructions__\n",
    "- Import CountVectorizer from sklearn.feature_extraction.text.\n",
    "- Fill missing values in df.Position_Extra using .fillna('') to replace NaNs with empty strings. Specify the additional keyword argument inplace=True so that you don't have to assign the result back to df.\n",
    "- Instantiate the CountVectorizer as vec_alphanumeric by specifying the token_pattern to be TOKENS_ALPHANUMERIC.\n",
    "- Fit vec_alphanumeric to df.Position_Extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 385 tokens in Position_Extra if we split on non-alpha numeric\n",
      "['1st', '2nd', '3rd', '4th', '56', '5th', '9th', 'a', 'ab', 'accountability', 'adaptive', 'addit', 'additional', 'adm', 'admin']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in training_df.Position_Extra\n",
    "training_df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(training_df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Great work! Treating only alpha-numeric characters as tokens gives you a smaller number of more meaningful tokens. You've got bag-of-words in the bag!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining text columns for tokenization\n",
    "In order to get a bag-of-words representation for all of the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string.\n",
    "\n",
    "In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. CountVectorizer expects each row to just be a single string, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string.\n",
    "\n",
    "In this exercise, you'll complete the function definition combine_text_columns(). When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method.\n",
    "\n",
    "Note that the function uses NUMERIC_COLUMNS and LABELS to determine which columns to drop. These lists have been loaded into the workspace.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instructions__\n",
    "- Use the .drop() method on data_frame with to_drop and axis= as arguments to drop the non-text data. Save the result as text_data.\n",
    "- Fill in missing values (inplace) in text_data with blanks (\"\"), using the .fillna() method.\n",
    "- Complete the .apply() method by writing a lambda function that uses the .join() method to join all the items in a row with a space in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Good job! You'll put this function to use in the next exercise to tokenize the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in a token?\n",
    "Now you will use combine_text_columns to convert all training text data in your DataFrame to a single vector that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method.\n",
    "\n",
    "You'll compare the effect of tokenizing using any non-whitespace characters as a token and using only alphanumeric characters as a token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instructions__\n",
    "- Import CountVectorizer from sklearn.feature_extraction.text.\n",
    "- Instantiate vec_basic and vec_alphanumeric using, respectively, the TOKENS_BASIC and TOKENS_ALPHANUMERIC patterns.\n",
    "- Create the text vector by using the combine_text_columns() function on df.\n",
    "- Using the .fit_transform() method with text_vector, fit and transform first vec_basic and then vec_alphanumeric. Print the number of tokens they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4757 tokens in the dataset\n",
      "There are 3284 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(training_df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wow, you're on your way to complete Data Domination! Notice that tokenizing on alpha-numeric tokens reduced the number of tokens, just as in the last exercise. We'll keep this in mind when building a better model with the Pipeline object next. See you in the next chapter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
